{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 DoF Pose from Semantic Keypoints #\n",
    "\n",
    "The following primarity comes from https://github.com/vaishak2future/posefromkeypoints.git\n",
    "\n",
    "The code is an implementation of https://www.seas.upenn.edu/~pavlakos/projects/object3d/\n",
    "Find the associated tutorial at:https://medium.com/@vaishakvk/geometric-deep-learning-for-pose-estimation-6af45da05922\n",
    "\n",
    "This is an adaptation of code used in Prof.Kostas Daniilidis' course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/mines_ws\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import json, random\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from src.keypoints_detection.hourglass import hg\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "import os\n",
    "#from os import join\n",
    "from time import time\n",
    "import numpy as np\n",
    "import cv2 \n",
    "\n",
    "os.makedirs('./models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keypoint Training ##\n",
    "\n",
    "The following code is what trains the keypoint detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \"\"\"The following defines how the model will load the data\"\"\"\n",
    "\n",
    "    def __init__(self, dataset_dir:str, is_train=True, transform=None):\n",
    "        \"\"\"Initialize Dataset\n",
    "\n",
    "        Args:\n",
    "            dataset_dir (str): path to the dataset.\n",
    "            is_train (bool, optional): Tracks id the dataset is a train dataset. Defaults to True.\n",
    "            transform (torch.transform, optional): pytorch transformations. Defaults to None.\n",
    "        \"\"\"\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.is_train = is_train\n",
    "        self.transform = transform\n",
    "        file_name = \"frame_data_train.json\" if is_train else \"frame_data_test.json\"\n",
    "\n",
    "        path = f\"{dataset_dir}/{file_name}\"\n",
    "        with open(path, 'r') as f:\n",
    "            self.data = dict(json.load(f))\n",
    "\n",
    "        self.img_names = list(self.data.keys())\n",
    "        \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.img_names[idx]\n",
    "\n",
    "        image_dir = self.data[image_name][\"img_dir\"]\n",
    "\n",
    "        image = cv2.imread(f\"{image_dir}/Images/{image_name}.png\")\n",
    "        # bb = [0,0,image.shape[1], image.shape[0]]\n",
    "        bb = self.data[image_name][\"bbox\"]\n",
    "        # image = Image.fromarray((image[:,:,:3]*255).astype(np.uint8))\n",
    "        image = Image.fromarray(image)\n",
    "        # bb = self.data[image_name][\"bbox\"]\n",
    "\n",
    "        keypoints = self.data[image_name][\"keypoints\"]\n",
    "        keypoints = np.array(keypoints)\n",
    "        # print(keypoints)\n",
    "        item = {'image': image, 'bb': bb, 'keypoints': keypoints}\n",
    "        # print(keypoints.shape)\n",
    "        if self.transform is not None:\n",
    "            item = self.transform(item)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformations\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "def generate_heatmap(heatmap, pt, sigma):\n",
    "    heatmap[int(pt[1])][int(pt[0])] = 1\n",
    "    heatmap = cv2.GaussianBlur(heatmap, sigma, 0)\n",
    "    am = np.amax(heatmap)\n",
    "    heatmap /= am\n",
    "    return heatmap\n",
    "\n",
    "\n",
    "class Blurr:\n",
    "    def __init__(self, radius) -> None:\n",
    "        import time\n",
    "        self.radius = radius\n",
    "        random.seed(time.time())\n",
    "\n",
    "    def __call__(self, sample) -> Any:\n",
    "        img = sample['image']\n",
    "        img = img.filter(ImageFilter.GaussianBlur(radius=random.uniform(2,4)))\n",
    "        enhancer = ImageEnhance.Brightness(img)\n",
    "        img = enhancer.enhance(random.uniform(0.5, 1))\n",
    "        sample['image'] = img\n",
    "        return sample\n",
    "\n",
    "\n",
    "class CropAndPad:\n",
    "\n",
    "    def __init__(self, out_size=(256,256)):\n",
    "        self.out_size = out_size[::-1]\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, bb = sample['image'], sample['bb']\n",
    "        img_size = image.size\n",
    "        min_x, min_y = bb[:2]\n",
    "        max_x, max_y = bb[2:]\n",
    "        center_x = (min_x + max_x) / 2\n",
    "        center_y = (min_y + max_y) / 2\n",
    "        width = max([max_x-min_x, max_y-min_y])\n",
    "        min_x = int(center_x) - int(width)//2\n",
    "        min_y = int(center_y) - int(width)//2\n",
    "        max_x = int(center_x) + int(width)//2\n",
    "        max_y = int(center_y) + int(width)//2\n",
    "        sample['image'] = image.crop(box=(min_x,min_y,max_x,max_y))\n",
    "        sample['orig_image'] = image\n",
    "        sample['center'] = np.array([center_x, center_y], dtype=np.float32)\n",
    "        sample['min'] = np.array([min_x, min_y], dtype=np.float32)\n",
    "        sample['scale'] = np.array([width/self.out_size[0]], dtype=np.float32)\n",
    "        sample['width'] = width\n",
    "        if width != self.out_size[0]:\n",
    "            sample['image'] = sample['image'].resize(self.out_size)\n",
    "        if 'mask' in sample:\n",
    "            sample['mask'] = sample['mask'].crop(box=(min_x,min_y,max_x,max_y)).resize(self.out_size)\n",
    "        if 'keypoints' in sample:\n",
    "            keypoints = sample['keypoints']\n",
    "            for i in range(keypoints.shape[0]):\n",
    "                # if keypoints[i,2] != 0:\n",
    "                if keypoints[i,0] < min_x or keypoints[i,0] > max_x or keypoints[i,1] < min_y or keypoints[i,1] > max_y:\n",
    "                    keypoints[i,:] = [0,0,0]\n",
    "                else:\n",
    "                    keypoints[i,:2] = (keypoints[i,:2]-np.array([min_x, min_y]))*self.out_size/width\n",
    "        sample['keypoints'] = keypoints\n",
    "        sample.pop('bb')\n",
    "        return sample\n",
    "\n",
    "# Convert keypoint locations to heatmaps\n",
    "class LocsToHeatmaps:\n",
    "\n",
    "    def __init__(self, img_size=(256,256), out_size=(64,64), sigma=1):\n",
    "        self.img_size = img_size\n",
    "        self.out_size = out_size\n",
    "        self.x_scale = 1.0 * out_size[0]/img_size[0]\n",
    "        self.y_scale = 1.0 * out_size[1]/img_size[1]\n",
    "        self.sigma=sigma\n",
    "        x = np.arange(0, out_size[1], dtype=np.float32)\n",
    "        y = np.arange(0, out_size[0], dtype=np.float32)\n",
    "        self.yg, self.xg = np.meshgrid(y,x, indexing='ij')\n",
    "        return\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sigma = 7\n",
    "        gaussian_hm = np.zeros((self.out_size[0], self.out_size[1], sample['keypoints'].shape[0]))\n",
    "        for i,keypoint in enumerate(sample['keypoints']):\n",
    "            if keypoint[2] != 0:\n",
    "                gaussian_hm[:,:,i] = generate_heatmap(gaussian_hm[:,:,i], tuple(keypoint[:-1].astype(np.int64) * self.x_scale), (sigma, sigma))\n",
    "        sample['keypoint_locs'] = sample['keypoints'][:,:2]\n",
    "        sample['visible_keypoints'] = sample['keypoints'][:,2]\n",
    "        sample['keypoint_heatmaps'] = gaussian_hm\n",
    "        return sample\n",
    "\n",
    "# Convert numpy arrays to Tensor objects\n",
    "# Permute the image dimensions\n",
    "class ToTensor:\n",
    "\n",
    "    def __init__(self, downsample_mask=False):\n",
    "        self.tt = transforms.ToTensor()\n",
    "        self.downsample_mask=downsample_mask\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample['image'] = self.tt(sample['image'])\n",
    "        if 'orig_image' in sample:\n",
    "            sample['orig_image'] = self.tt(sample['orig_image'])\n",
    "        if 'mask' in sample:\n",
    "            if self.downsample_mask:\n",
    "                sample['mask'] = self.tt(sample['mask'].resize((64,64), Image.ANTIALIAS))\n",
    "            else:\n",
    "                sample['mask'] = self.tt(sample['mask'])\n",
    "        if 'in_mask' in sample:\n",
    "            sample['in_mask'] = self.tt(sample['in_mask'])\n",
    "            # sample['in_mask'] = sample['in_mask'].unsqueeze(0)\n",
    "        if 'keypoint_heatmaps' in sample:\n",
    "            sample['keypoint_heatmaps'] =\\\n",
    "                torch.from_numpy(sample['keypoint_heatmaps'].astype(np.float32).transpose(2,0,1))\n",
    "            sample['keypoint_locs'] =\\\n",
    "                torch.from_numpy(sample['keypoint_locs'].astype(np.float32))\n",
    "            sample['visible_keypoints'] =\\\n",
    "                torch.from_numpy(sample['visible_keypoints'].astype(np.float32))\n",
    "        return sample\n",
    "\n",
    "class Normalize:\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample['image'] = 2*(sample['image']-0.5)\n",
    "        if 'in_mask' in sample:\n",
    "            sample['in_mask'] = 2*(sample['in_mask']-0.5)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "\n",
    "    def __init__(self, dataset_dir, learning_rate, model_path: str = None):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        train_transform_list = [Blurr(2.2), CropAndPad(out_size=(256, 256)),LocsToHeatmaps(out_size=(64, 64)),ToTensor(),Normalize()]\n",
    "        test_transform_list = [CropAndPad(out_size=(256, 256)),LocsToHeatmaps(out_size=(64, 64)),ToTensor(),Normalize()]\n",
    "        self.train_ds = Dataset(is_train=True, transform=transforms.Compose(train_transform_list), dataset_dir=dataset_dir)\n",
    "        self.test_ds = Dataset(is_train=False, transform=transforms.Compose(test_transform_list), dataset_dir=dataset_dir)\n",
    "\n",
    "        self.model = hg(num_stacks=1, num_blocks=1, num_classes=10).to(self.device)\n",
    "\n",
    "        if model_path is not None:\n",
    "            print(\"loading model from checkpoint\")\n",
    "            try:\n",
    "                checkpoint = torch.load(model_path)\n",
    "                self.model.load_state_dict(checkpoint['model'])\n",
    "            except:\n",
    "                print(\"No checkpoint loaded\")\n",
    "        else:\n",
    "            print(\"Not using checkpointed model\")\n",
    "        # define loss function and optimizer\n",
    "        self.heatmap_loss = torch.nn.MSELoss().to(self.device) # for Global loss\n",
    "        self.optimizer = torch.optim.RMSprop(self.model.parameters(),\n",
    "                                             lr = learning_rate)#2.5e-4)\n",
    "        self.train_data_loader = DataLoader(self.train_ds, batch_size=16,\n",
    "                                            num_workers=8,\n",
    "                                            pin_memory=True,\n",
    "                                            shuffle=True)\n",
    "        self.test_data_loader = DataLoader(self.test_ds, batch_size=32,\n",
    "                                           num_workers=8,\n",
    "                                           pin_memory=True,\n",
    "                                           shuffle=True)\n",
    "\n",
    "        self.summary_iters = []\n",
    "        self.losses = []\n",
    "        self.pcks = []\n",
    "        self.running_losses = []\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        self.total_step_count = 0\n",
    "        start_time = time()\n",
    "        for epoch in range(1,num_epochs+1):\n",
    "\n",
    "            print(\"Epoch%d/%d\"%\n",
    "                    (epoch,num_epochs), end=\"\\r\")\n",
    "\n",
    "            running_loss = 0\n",
    "\n",
    "            for step, batch in enumerate(self.train_data_loader):\n",
    "                self.model.train()\n",
    "                batch = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v for k,v in batch.items()}\n",
    "                self.optimizer.zero_grad()\n",
    "                pred_heatmap_list = self.model(batch['image'])\n",
    "                loss = self.heatmap_loss(pred_heatmap_list[-1], batch['keypoint_heatmaps'])\n",
    "                loss.backward()\n",
    "                self.optimizer.step()                                          \n",
    "                \n",
    "                self.total_step_count += 1\n",
    "\n",
    "                running_loss += loss.detach()\n",
    "\n",
    "                if step % 10 == 0:\n",
    "                    print(f\"running loss at step {step} = \\t{running_loss}\", end=\"\\r\")\n",
    "            \n",
    "            self.running_losses.append(running_loss)\n",
    "            print(f\"Epoch {epoch} / {num_epochs} total Loss\\t\")\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Savig Checkpoint at epoch {epoch}\")\n",
    "                checkpoint = {'model': self.model.state_dict()}\n",
    "                torch.save(checkpoint, './output/model_checkpoint.pt')\n",
    "                \n",
    "        checkpoint = {'model': self.model.state_dict()}\n",
    "        torch.save(checkpoint, './models/kpt_checkpoint.pt')\n",
    "\n",
    "    def save(self, checkpoint_name):\n",
    "        checkpoint = {'model': self.model.state_dict()}\n",
    "        print(\"saving checkpoint\")\n",
    "        torch.save(checkpoint, f'./models/{checkpoint_name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"./data/NewData\"\n",
    "\n",
    "# if the simulated data is given in an improper format\n",
    "%run ~/mines_ws/src/data_collection/preprocessing/fix_json.py {data_directory} DescriptiveFrameData.json\n",
    "data_directory += \"/accumulated_data\"\n",
    "\n",
    "model_path = \"./models/model_checkpoint.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(dataset_dir=data_directory, learning_rate=0.00005, model_path=model_path)\n",
    "trainer.train(num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save(\"kpt_checkpoint\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
