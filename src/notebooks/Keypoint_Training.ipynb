{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 DoF Pose from Semantic Keypoints #\n",
    "\n",
    "The following primarity comes from https://github.com/vaishak2future/posefromkeypoints.git\n",
    "\n",
    "The code is an implementation of https://www.seas.upenn.edu/~pavlakos/projects/object3d/\n",
    "Find the associated tutorial at:https://medium.com/@vaishakvk/geometric-deep-learning-for-pose-estimation-6af45da05922\n",
    "\n",
    "This is an adaptation of code used in Prof.Kostas Daniilidis' course. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Change the directory to ws directiory. Must be run within dockercontainter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:393: UserWarning: using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n",
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mines/mines_ws\n"
     ]
    }
   ],
   "source": [
    "%cd ~/mines_ws\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import json, random\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from src.keypoints_detection.hourglass import hg\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "import os\n",
    "#from os import join\n",
    "from time import time\n",
    "import numpy as np\n",
    "import cv2 \n",
    "\n",
    "os.makedirs('./models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keypoint Training ##\n",
    "\n",
    "The following code is what trains the keypoint detection model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "The cell below defines the dataset used for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \"\"\"The following defines how the model will load the data\"\"\"\n",
    "\n",
    "    def __init__(self, dataset_dir:str, is_train=True, transform=None):\n",
    "        \"\"\"Initialize Dataset\n",
    "\n",
    "        Args:\n",
    "            dataset_dir (str): path to the dataset.\n",
    "            is_train (bool, optional): Tracks id the dataset is a train dataset. Defaults to True.\n",
    "            transform (torch.transform, optional): pytorch transformations. Defaults to None.\n",
    "        \"\"\"\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.is_train = is_train\n",
    "        self.transform = transform\n",
    "        file_name = \"train_data.json\" if is_train else \"test_data.json\"\n",
    "\n",
    "        path = f\"{dataset_dir}/{file_name}\"\n",
    "        with open(path, 'r') as f:\n",
    "            self.data = dict(json.load(f))\n",
    "\n",
    "        self.img_names = list(self.data.keys())\n",
    "        \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.img_names[idx]\n",
    "\n",
    "        image_dir = self.data[image_name][\"img_dir\"]\n",
    "\n",
    "        image = cv2.imread(f\"{self.dataset_dir}/Images/{image_dir}/{image_name}.png\")\n",
    "        # bb = [0,0,image.shape[1], image.shape[0]]\n",
    "        bb = self.data[image_name][\"bbox\"]\n",
    "        # image = Image.fromarray((image[:,:,:3]*255).astype(np.uint8))\n",
    "        image = Image.fromarray(image)\n",
    "        # bb = self.data[image_name][\"bbox\"]\n",
    "\n",
    "        keypoints = self.data[image_name][\"keypoints\"]\n",
    "        keypoints = np.array(keypoints)\n",
    "        # print(keypoints)\n",
    "        item = {'image': image, 'bb': bb, 'keypoints': keypoints}\n",
    "        # print(keypoints.shape)\n",
    "        if self.transform is not None:\n",
    "            item = self.transform(item)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformations\n",
    "The following defines the necessary transformations, including\n",
    "- Blurr: applies blur filter and dims image. Is necessary for training on simulated dataset\n",
    "- Crop and Pad: Crops image to bounding box and bad to square image\n",
    "- Locs to Heatmaps: Create a heatmap for each pixel\n",
    "- To Tensor: converts necessary information into a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformations\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "def generate_heatmap(heatmap, pt, sigma):\n",
    "    heatmap[int(pt[1])][int(pt[0])] = 1\n",
    "    heatmap = cv2.GaussianBlur(heatmap, sigma, 0)\n",
    "    am = np.amax(heatmap)\n",
    "    heatmap /= am\n",
    "    return heatmap\n",
    "\n",
    "\n",
    "class Blurr:\n",
    "    def __init__(self, radius) -> None:\n",
    "        import time\n",
    "        self.radius = radius\n",
    "        random.seed(time.time())\n",
    "\n",
    "    def __call__(self, sample) -> Any:\n",
    "        img = sample['image']\n",
    "        img = img.filter(ImageFilter.GaussianBlur(radius=random.uniform(2,4)))\n",
    "        enhancer = ImageEnhance.Brightness(img)\n",
    "        img = enhancer.enhance(random.uniform(0.5, 1))\n",
    "        sample['image'] = img\n",
    "        return sample\n",
    "\n",
    "\n",
    "class CropAndPad:\n",
    "\n",
    "    def __init__(self, out_size=(256,256)):\n",
    "        self.out_size = out_size[::-1]\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, bb = sample['image'], sample['bb']\n",
    "        img_size = image.size\n",
    "        min_x, min_y = bb[:2]\n",
    "        max_x, max_y = bb[2:]\n",
    "        center_x = (min_x + max_x) / 2\n",
    "        center_y = (min_y + max_y) / 2\n",
    "        width = max([max_x-min_x, max_y-min_y])\n",
    "        min_x = int(center_x) - int(width)//2\n",
    "        min_y = int(center_y) - int(width)//2\n",
    "        max_x = int(center_x) + int(width)//2\n",
    "        max_y = int(center_y) + int(width)//2\n",
    "        sample['image'] = image.crop(box=(min_x,min_y,max_x,max_y))\n",
    "        sample['orig_image'] = image\n",
    "        sample['center'] = np.array([center_x, center_y], dtype=np.float32)\n",
    "        sample['min'] = np.array([min_x, min_y], dtype=np.float32)\n",
    "        sample['scale'] = np.array([width/self.out_size[0]], dtype=np.float32)\n",
    "        sample['width'] = width\n",
    "        if width != self.out_size[0]:\n",
    "            sample['image'] = sample['image'].resize(self.out_size)\n",
    "        if 'mask' in sample:\n",
    "            sample['mask'] = sample['mask'].crop(box=(min_x,min_y,max_x,max_y)).resize(self.out_size)\n",
    "        if 'keypoints' in sample:\n",
    "            keypoints = sample['keypoints']\n",
    "            for i in range(keypoints.shape[0]):\n",
    "                # if keypoints[i,2] != 0:\n",
    "                if keypoints[i,0] < min_x or keypoints[i,0] > max_x or keypoints[i,1] < min_y or keypoints[i,1] > max_y:\n",
    "                    keypoints[i,:] = [0,0,0]\n",
    "                else:\n",
    "                    keypoints[i,:2] = (keypoints[i,:2]-np.array([min_x, min_y]))*self.out_size/width\n",
    "        sample['keypoints'] = keypoints\n",
    "        sample.pop('bb')\n",
    "        return sample\n",
    "\n",
    "# Convert keypoint locations to heatmaps\n",
    "class LocsToHeatmaps:\n",
    "\n",
    "    def __init__(self, img_size=(256,256), out_size=(64,64), sigma=1):\n",
    "        self.img_size = img_size\n",
    "        self.out_size = out_size\n",
    "        self.x_scale = 1.0 * out_size[0]/img_size[0]\n",
    "        self.y_scale = 1.0 * out_size[1]/img_size[1]\n",
    "        self.sigma=sigma\n",
    "        x = np.arange(0, out_size[1], dtype=np.float32)\n",
    "        y = np.arange(0, out_size[0], dtype=np.float32)\n",
    "        self.yg, self.xg = np.meshgrid(y,x, indexing='ij')\n",
    "        return\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sigma = 7\n",
    "        gaussian_hm = np.zeros((self.out_size[0], self.out_size[1], sample['keypoints'].shape[0]))\n",
    "        for i,keypoint in enumerate(sample['keypoints']):\n",
    "            if keypoint[2] != 0:\n",
    "                gaussian_hm[:,:,i] = generate_heatmap(gaussian_hm[:,:,i], tuple(keypoint[:-1].astype(np.int64) * self.x_scale), (sigma, sigma))\n",
    "        sample['keypoint_locs'] = sample['keypoints'][:,:2]\n",
    "        sample['visible_keypoints'] = sample['keypoints'][:,2]\n",
    "        sample['keypoint_heatmaps'] = gaussian_hm\n",
    "        return sample\n",
    "\n",
    "# Convert numpy arrays to Tensor objects\n",
    "# Permute the image dimensions\n",
    "class ToTensor:\n",
    "\n",
    "    def __init__(self, downsample_mask=False):\n",
    "        self.tt = transforms.ToTensor()\n",
    "        self.downsample_mask=downsample_mask\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample['image'] = self.tt(sample['image'])\n",
    "        if 'orig_image' in sample:\n",
    "            sample['orig_image'] = self.tt(sample['orig_image'])\n",
    "        if 'mask' in sample:\n",
    "            if self.downsample_mask:\n",
    "                sample['mask'] = self.tt(sample['mask'].resize((64,64), Image.ANTIALIAS))\n",
    "            else:\n",
    "                sample['mask'] = self.tt(sample['mask'])\n",
    "        if 'in_mask' in sample:\n",
    "            sample['in_mask'] = self.tt(sample['in_mask'])\n",
    "            # sample['in_mask'] = sample['in_mask'].unsqueeze(0)\n",
    "        if 'keypoint_heatmaps' in sample:\n",
    "            sample['keypoint_heatmaps'] =\\\n",
    "                torch.from_numpy(sample['keypoint_heatmaps'].astype(np.float32).transpose(2,0,1))\n",
    "            sample['keypoint_locs'] =\\\n",
    "                torch.from_numpy(sample['keypoint_locs'].astype(np.float32))\n",
    "            sample['visible_keypoints'] =\\\n",
    "                torch.from_numpy(sample['visible_keypoints'].astype(np.float32))\n",
    "        return sample\n",
    "\n",
    "class Normalize:\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample['image'] = 2*(sample['image']-0.5)\n",
    "        if 'in_mask' in sample:\n",
    "            sample['in_mask'] = 2*(sample['in_mask']-0.5)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainer\n",
    "Defines the model trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "\n",
    "    def __init__(self, dataset_dir, learning_rate, model_path: str = None):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        train_transform_list = [Blurr(2.2), CropAndPad(out_size=(256, 256)),LocsToHeatmaps(out_size=(64, 64)),ToTensor(),Normalize()]\n",
    "        test_transform_list = [CropAndPad(out_size=(256, 256)),LocsToHeatmaps(out_size=(64, 64)),ToTensor(),Normalize()]\n",
    "        self.train_ds = Dataset(is_train=True, transform=transforms.Compose(train_transform_list), dataset_dir=dataset_dir)\n",
    "        self.test_ds = Dataset(is_train=False, transform=transforms.Compose(test_transform_list), dataset_dir=dataset_dir)\n",
    "\n",
    "        self.model = hg(num_stacks=1, num_blocks=1, num_classes=10).to(self.device)\n",
    "\n",
    "        if model_path is not None:\n",
    "            print(\"loading model from checkpoint\")\n",
    "            try:\n",
    "                checkpoint = torch.load(model_path)\n",
    "                self.model.load_state_dict(checkpoint['model'])\n",
    "            except:\n",
    "                print(\"No checkpoint loaded\")\n",
    "        else:\n",
    "            print(\"Not using checkpointed model\")\n",
    "        # define loss function and optimizer\n",
    "        self.heatmap_loss = torch.nn.MSELoss().to(self.device) # for Global loss\n",
    "        self.optimizer = torch.optim.RMSprop(self.model.parameters(),\n",
    "                                             lr = learning_rate)#2.5e-4)\n",
    "        self.train_data_loader = DataLoader(self.train_ds, batch_size=16,\n",
    "                                            num_workers=8,\n",
    "                                            pin_memory=True,\n",
    "                                            shuffle=True)\n",
    "        self.test_data_loader = DataLoader(self.test_ds, batch_size=32,\n",
    "                                           num_workers=8,\n",
    "                                           pin_memory=True,\n",
    "                                           shuffle=True)\n",
    "\n",
    "        self.summary_iters = []\n",
    "        self.losses = []\n",
    "        self.pcks = []\n",
    "        self.running_losses = []\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        self.total_step_count = 0\n",
    "        start_time = time()\n",
    "        for epoch in range(1,num_epochs+1):\n",
    "\n",
    "            print(\"Epoch%d/%d\"%\n",
    "                    (epoch,num_epochs), end=\"\\r\")\n",
    "\n",
    "            running_loss = 0\n",
    "\n",
    "            for step, batch in enumerate(self.train_data_loader):\n",
    "                self.model.train()\n",
    "                batch = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v for k,v in batch.items()}\n",
    "                self.optimizer.zero_grad()\n",
    "                pred_heatmap_list = self.model(batch['image'])\n",
    "                loss = self.heatmap_loss(pred_heatmap_list[-1], batch['keypoint_heatmaps'])\n",
    "                loss.backward()\n",
    "                self.optimizer.step()                                          \n",
    "                \n",
    "                self.total_step_count += 1\n",
    "\n",
    "                running_loss += loss.detach()\n",
    "\n",
    "                if step % 10 == 0:\n",
    "                    print(f\"running loss at step {step} = \\t{running_loss}\", end=\"\\r\")\n",
    "            \n",
    "            self.running_losses.append(running_loss)\n",
    "            print(f\"Epoch {epoch} / {num_epochs} total Loss\\t\")\n",
    "\n",
    "\n",
    "            # print(f\"Savig Checkpoint at epoch {epoch}\")\n",
    "            checkpoint = {'model': self.model.state_dict()}\n",
    "            torch.save(checkpoint, './models/kpt_checkpoint.pt')\n",
    "                \n",
    "\n",
    "\n",
    "    def save(self, checkpoint_name):\n",
    "        checkpoint = {'model': self.model.state_dict()}\n",
    "        print(\"saving checkpoint\")\n",
    "        torch.save(checkpoint, f'./models/{checkpoint_name}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/simulated AllFrameData.json 0.8\n",
      "Creating train set of 80% of dataset\n",
      "Creating test set of 20% of dataset\n"
     ]
    }
   ],
   "source": [
    "data_directory = \"./data/simulated\"\n",
    "model_path = \"./models/model_checkpoint.pt\"\n",
    "\n",
    "# if no train/test is created, run the train_test python script\n",
    "%run ~/mines_ws/src/data_collection/preprocessing/train_test.py {data_directory} AllFrameData.json 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from checkpoint\n",
      "Epoch 1 / 50 total Loss\t \t0.38753175735473633\n",
      "Savig Checkpoint at epoch 1\n",
      "Epoch 2 / 50 total Loss\t \t0.004236075095832348\n",
      "Savig Checkpoint at epoch 2\n",
      "Epoch 3 / 50 total Loss\t \t0.0006401329301297665\n",
      "Savig Checkpoint at epoch 3\n",
      "Epoch 4 / 50 total Loss\t \t0.0005921200499869883\n",
      "Savig Checkpoint at epoch 4\n",
      "Epoch 5 / 50 total Loss\t \t0.0005604593898169696\n",
      "Savig Checkpoint at epoch 5\n",
      "Epoch 6 / 50 total Loss\t \t0.0005327572580426931\n",
      "Savig Checkpoint at epoch 6\n",
      "Epoch 7 / 50 total Loss\t \t0.0005081607378087938\n",
      "Savig Checkpoint at epoch 7\n",
      "Epoch 8 / 50 total Loss\t \t0.00048561327275820076\n",
      "Savig Checkpoint at epoch 8\n",
      "Epoch 9 / 50 total Loss\t \t0.00046716173528693616\n",
      "Savig Checkpoint at epoch 9\n",
      "Epoch 10 / 50 total Loss\t\t0.00045031923218630254\n",
      "Savig Checkpoint at epoch 10\n",
      "Epoch 11 / 50 total Loss\t\t0.000434773915912956\n",
      "Savig Checkpoint at epoch 11\n",
      "Epoch 12 / 50 total Loss\t\t0.00041972444159910083\n",
      "Savig Checkpoint at epoch 12\n",
      "Epoch 13 / 50 total Loss\t\t0.00040584945236332715\n",
      "Savig Checkpoint at epoch 13\n",
      "Epoch 14 / 50 total Loss\t\t0.00039091994403861463\n",
      "Savig Checkpoint at epoch 14\n",
      "Epoch 15 / 50 total Loss\t\t0.00037592428270727396\n",
      "Savig Checkpoint at epoch 15\n",
      "Epoch 16 / 50 total Loss\t\t0.0003626426332630217\n",
      "Savig Checkpoint at epoch 16\n",
      "Epoch 17 / 50 total Loss\t\t0.00035123739507980645\n",
      "Savig Checkpoint at epoch 17\n",
      "Epoch 18 / 50 total Loss\t\t0.00034070436959154904\n",
      "Savig Checkpoint at epoch 18\n",
      "Epoch 19 / 50 total Loss\t\t0.00033086640178225935\n",
      "Savig Checkpoint at epoch 19\n",
      "Epoch 20 / 50 total Loss\t\t0.00032193175866268575\n",
      "Savig Checkpoint at epoch 20\n",
      "Epoch 21 / 50 total Loss\t\t0.0003136643790639937\n",
      "Savig Checkpoint at epoch 21\n",
      "Epoch 22 / 50 total Loss\t\t0.00030614371644333005\n",
      "Savig Checkpoint at epoch 22\n",
      "Epoch 23 / 50 total Loss\t\t0.00029917212668806314\n",
      "Savig Checkpoint at epoch 23\n",
      "Epoch 24 / 50 total Loss\t\t0.0002925205626524985\n",
      "Savig Checkpoint at epoch 24\n",
      "Epoch 25 / 50 total Loss\t\t0.00028628300060518086\n",
      "Savig Checkpoint at epoch 25\n",
      "Epoch 26 / 50 total Loss\t\t0.0002804311807267368\n",
      "Savig Checkpoint at epoch 26\n",
      "Epoch 27 / 50 total Loss\t\t0.00027484988095238805\n",
      "Savig Checkpoint at epoch 27\n",
      "Epoch 28 / 50 total Loss\t\t0.00026947323931381106\n",
      "Savig Checkpoint at epoch 28\n",
      "Epoch 29 / 50 total Loss\t\t0.0002643735206220299\n",
      "Savig Checkpoint at epoch 29\n",
      "Epoch 30 / 50 total Loss\t\t0.0002595168771222234\n",
      "Savig Checkpoint at epoch 30\n",
      "Epoch 31 / 50 total Loss\t\t0.0002547490585129708\n",
      "Savig Checkpoint at epoch 31\n",
      "Epoch 32 / 50 total Loss\t\t0.0002501138369552791\n",
      "Savig Checkpoint at epoch 32\n",
      "Epoch 33 / 50 total Loss\t\t0.0002456983784213662\n",
      "Savig Checkpoint at epoch 33\n",
      "Epoch 34 / 50 total Loss\t\t0.0002413467736914754\n",
      "Savig Checkpoint at epoch 34\n",
      "Epoch 35 / 50 total Loss\t\t0.00023728467931505293\n",
      "Savig Checkpoint at epoch 35\n",
      "Epoch 36 / 50 total Loss\t\t0.00023338317987509072\n",
      "Savig Checkpoint at epoch 36\n",
      "Epoch 37 / 50 total Loss\t\t0.00022958328190725297\n",
      "Savig Checkpoint at epoch 37\n",
      "Epoch 38 / 50 total Loss\t\t0.00022602920944336802\n",
      "Savig Checkpoint at epoch 38\n",
      "Epoch 39 / 50 total Loss\t\t0.00022255934891290963\n",
      "Savig Checkpoint at epoch 39\n",
      "Epoch 40 / 50 total Loss\t\t0.00021924765314906836\n",
      "Savig Checkpoint at epoch 40\n",
      "Epoch 41 / 50 total Loss\t\t0.00021577588631771505\n",
      "Savig Checkpoint at epoch 41\n",
      "Epoch 42 / 50 total Loss\t\t0.0002123559679603204\n",
      "Savig Checkpoint at epoch 42\n",
      "Epoch 43 / 50 total Loss\t\t0.00020910284365527332\n",
      "Savig Checkpoint at epoch 43\n",
      "Epoch 44 / 50 total Loss\t\t0.00020596038666553795\n",
      "Savig Checkpoint at epoch 44\n",
      "Epoch 45 / 50 total Loss\t\t0.00020318126189522445\n",
      "Savig Checkpoint at epoch 45\n",
      "Epoch 46 / 50 total Loss\t\t0.00020028102153446525\n",
      "Savig Checkpoint at epoch 46\n",
      "Epoch 47 / 50 total Loss\t\t0.00019748954218812287\n",
      "Savig Checkpoint at epoch 47\n",
      "Epoch 48 / 50 total Loss\t\t0.00019475346198305488\n",
      "Savig Checkpoint at epoch 48\n",
      "Epoch 49 / 50 total Loss\t\t0.00019199249800294638\n",
      "Savig Checkpoint at epoch 49\n",
      "Epoch 50 / 50 total Loss\t\t0.00018937060667667538\n",
      "Savig Checkpoint at epoch 50\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(dataset_dir=data_directory, learning_rate=0.00005, model_path=model_path)\n",
    "trainer.train(num_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model, does not need to be run sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save(\"kpt_checkpoint\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
