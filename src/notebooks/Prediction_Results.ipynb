{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"./src\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.io import read_image\n",
    "from src.bounding_box import BBoxModel\n",
    "from src.image_transformations.coordinate_transforms import *\n",
    "from src.bounding_box import BBoxModel\n",
    "from src.keypoints_detection.keypoint_model import KPModel\n",
    "import PIL\n",
    "import cv2\n",
    "from src.keypoints_detection.hourglass import hg\n",
    "from scipy.spatial.transform import Rotation\n",
    "import os\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "BBOX_MODEL_PATH = \"./models/bbox_net_quick.pth\"\n",
    "KP_MODEL_PATH = \"./models/model_checkpoint_3.pt\"\n",
    "\n",
    "test_dir = './data/GroundTruth'\n",
    "\n",
    "bbox_model = BBoxModel(BBOX_MODEL_PATH)\n",
    "kp_model = KPModel(KP_MODEL_PATH)\n",
    "\n",
    "print(f\"Using device: {bbox_model.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(image_name):\n",
    "    img = cv2.imread(f\"{test_dir}/color/{image_name}.png\")\n",
    "    img_pill = PIL.Image.fromarray(img)\n",
    "    depth_img = np.load(f'{test_dir}/depth/{image_name}.npy')\n",
    "    K = IntrinsicsMatrix()\n",
    "\n",
    "    bbox, score = bbox_model.find_bbox(img_pill)\n",
    "\n",
    "    if bbox is not None:\n",
    "        kpts = kp_model.predict(img, bbox)\n",
    "        # try:\n",
    "        rotation, translation, img, _ = kp_model.predict_position(K, depth_img, 12, img)\n",
    "        # except:\n",
    "        #     print('raised exception predicting pose')\n",
    "        #     return None\n",
    "        if translation is not None and rotation is not None:\n",
    "            return TransformationMatrix(R=rotation, t=translation)\n",
    "        else:\n",
    "            print('failure to predict pose')\n",
    "            return None\n",
    "    else:\n",
    "        print('failure to predict bbox')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700082959447\n",
      "1700083030544\n",
      "1700083066419\n",
      "1700083079394\n",
      "1700083113121\n",
      "1700083139014\n",
      "rejected out of frame image\n",
      "rejected out of frame image\n",
      "rejected out of frame image\n",
      "1700083573884\n",
      "rejected out of frame image\n",
      "1700083778169\n",
      "1700083803525\n",
      "1700083820703\n",
      "1700083847556\n",
      "1700083865040\n",
      "1700083880259\n",
      "rejected out of frame image\n",
      "1700084198296\n",
      "1700084225173\n",
      "1700084245105\n",
      "1700084272193\n",
      "1700084293026\n",
      "1700088014586\n",
      "1700088095696\n",
      "1700088116871\n",
      "1700088143424\n",
      "1700088154181\n",
      "1700088168216\n",
      "1700088180617\n",
      "rejected out of frame image\n",
      "rejected out of frame image\n",
      "1700088326692\n",
      "1700088342543\n",
      "1700088358620\n",
      "1700088408247\n",
      "1700088418613\n",
      "rejected out of frame image\n",
      "rejected out of frame image\n",
      "1700088639168\n",
      "1700088655968\n",
      "1700088681678\n",
      "1700088693537\n",
      "1700088711575\n",
      "1700088726237\n",
      "1700088746119\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/GroundTruth/fuelcap_data.csv\")\n",
    "\n",
    "samples = []\n",
    "num_errors = 0\n",
    "for idx, row in df.iterrows():\n",
    "    if idx == 0:\n",
    "        continue\n",
    "    if row[\"OUT_OF_FRAME\"] == True:\n",
    "        print('rejected out of frame image')\n",
    "        continue\n",
    "    name = row[\"image_name\"]\n",
    "    x = row[\"dX\"]\n",
    "    y = row[\"dY\"]\n",
    "    z = row[\"dZ\"] - (25 / 25.4)\n",
    "    angle_mount = row[\"angle_mount\"]\n",
    "    angle_cap = row[\"angle_cap\"]\n",
    "\n",
    "    sample = dict()\n",
    "    sample['image_name'] = name\n",
    "    sample['measured_X'] = x\n",
    "    sample['measured_Y'] = y\n",
    "    sample['measured_Z'] = z\n",
    "    sample['measured_angle_mount'] = angle_mount\n",
    "    sample['measured_angle_cap'] = angle_cap\n",
    "\n",
    "    H_ground_truth = calculate_matrix(x, y, z, angle_mount, angle_cap, units='in')\n",
    "    kp_model.reset_positions()\n",
    "    H_prediction = make_prediction(name)\n",
    "\n",
    "    sample['ground_truth_translation'] = H_ground_truth.as_pos_and_quat()[0].tolist()\n",
    "    sample['ground_truth_rotation'] = H_ground_truth.as_pos_and_quat()[1].tolist()\n",
    "\n",
    "    if H_prediction is not None:\n",
    "        print(name)\n",
    "        sample['prediction_translation'] = H_prediction.as_pos_and_quat()[0].tolist()\n",
    "        sample['prediction_rotation'] = H_prediction.as_pos_and_quat()[1].tolist()\n",
    "    else:\n",
    "        sample['prediction_translation'] = \"prediction error\"\n",
    "        sample['prediction_rotation'] = \"prediction error\"\n",
    "        num_errors += 1\n",
    "    \n",
    "    samples.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully collected 37 samples out of 37\n",
      "\n",
      "First Sample:\n",
      "name=1700082959447\n",
      "ground truth translation=[154.42916870117188, -199.4399871826172, 497.60870361328125]\n",
      "ground truth rotation=[3.14156241e+00 1.06288809e-03 3.14107500e+00]\n",
      "predicted translation=[182.816162109375, -200.44960021972656, 506.5]\n",
      "predicted rotation=[3.00015376 0.05467823 3.09309607]\n"
     ]
    }
   ],
   "source": [
    "print(f'Successfully collected {len(samples) - num_errors} samples out of {len(samples)}')\n",
    "print(f'\\nFirst Sample:')\n",
    "print(f'name={samples[0][\"image_name\"]}')\n",
    "print(f'ground truth translation={samples[0][\"ground_truth_translation\"]}')\n",
    "print(f'ground truth rotation={Rotation.from_quat(samples[0][\"ground_truth_rotation\"]).as_euler(\"xyz\")}')\n",
    "print(f'predicted translation={samples[0][\"prediction_translation\"]}')\n",
    "print(f'predicted rotation={Rotation.from_quat(samples[0][\"prediction_rotation\"]).as_euler(\"xyz\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Save results\n",
    "with open('./data/GroundTruth/prediction_results.json', 'w') as f:\n",
    "    json.dump(samples, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
